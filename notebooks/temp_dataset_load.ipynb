{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T06:45:17.934290Z",
     "start_time": "2019-07-09T06:45:17.867272Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('..')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T06:45:19.199142Z",
     "start_time": "2019-07-09T06:45:19.115462Z"
    }
   },
   "outputs": [],
   "source": [
    "from train import *\n",
    "from data import format_thing, get_id_for_comments, thread2tree, get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T06:45:47.704015Z",
     "start_time": "2019-07-09T06:45:47.590248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--local_rank'], dest='local_rank', nargs=None, const=None, default=-1, type=<class 'int'>, choices=None, help='Local rank for distributed training (-1: not distributed)', metavar=None)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--dataset_path\", type=str, default=\"../data/reddit_threads/\", help=\"Path or url of the dataset. If empty download from S3.\")\n",
    "parser.add_argument(\"--dataset_cache\", type=str, default='./dataset_cache', help=\"Path or url of the dataset cache\")\n",
    "parser.add_argument(\"--model_checkpoint\", type=str, default=\"openai-gpt\", help=\"Path, url or short name of the model\")\n",
    "parser.add_argument(\"--num_candidates\", type=int, default=2, help=\"Number of candidates for training\")\n",
    "parser.add_argument(\"--max_history\", type=int, default=2, help=\"Number of previous exchanges to keep in history\")\n",
    "parser.add_argument(\"--train_batch_size\", type=int, default=4, help=\"Batch size for training\")\n",
    "parser.add_argument(\"--valid_batch_size\", type=int, default=4, help=\"Batch size for validation\")\n",
    "parser.add_argument(\"--gradient_accumulation_steps\", type=int, default=8, help=\"Accumulate gradients on several steps\")\n",
    "parser.add_argument(\"--lr\", type=float, default=6.25e-5, help=\"Learning rate\")\n",
    "parser.add_argument(\"--lm_coef\", type=float, default=1.0, help=\"LM loss coefficient\")\n",
    "parser.add_argument(\"--mc_coef\", type=float, default=1.0, help=\"Multiple-choice loss coefficient\")\n",
    "parser.add_argument(\"--max_norm\", type=float, default=1.0, help=\"Clipping gradient norm\")\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=3, help=\"Number of training epochs\")\n",
    "parser.add_argument(\"--personality_permutations\", type=int, default=1, help=\"Number of permutations of personality sentences\")\n",
    "parser.add_argument(\"--eval_before_start\", action='store_true', help=\"If true start with a first evaluation before training\")\n",
    "parser.add_argument(\"--device\", type=str, default=\"cuda\" if torch.cuda.is_available() else \"cpu\", help=\"Device (cuda or cpu)\")\n",
    "parser.add_argument(\"--fp16\", type=str, default=\"\", help=\"Set to O0, O1, O2 or O3 for fp16 training (see apex documentation)\")\n",
    "parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"Local rank for distributed training (-1: not distributed)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T06:45:47.903975Z",
     "start_time": "2019-07-09T06:45:47.821880Z"
    }
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T06:45:48.096670Z",
     "start_time": "2019-07-09T06:45:47.999215Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:../train.py:Running process -1\n",
      "INFO:../train.py:Arguments: Namespace(dataset_cache='./dataset_cache', dataset_path='../data/reddit_threads/', device='cuda', eval_before_start=False, fp16='', gradient_accumulation_steps=8, lm_coef=1.0, local_rank=-1, lr=6.25e-05, max_history=2, max_norm=1.0, mc_coef=1.0, model_checkpoint='openai-gpt', n_epochs=3, num_candidates=2, personality_permutations=1, train_batch_size=4, valid_batch_size=4)\n"
     ]
    }
   ],
   "source": [
    "# logging is set to INFO (resp. WARN) for main (resp. auxiliary) process. logger.info => log main process only, logger.warning => log all processes\n",
    "logging.basicConfig(level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN)\n",
    "logger.warning(\"Running process %d\", args.local_rank)  # This is a logger.warning: it will be printed by all distributed processes\n",
    "logger.info(\"Arguments: %s\", pformat(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check dataloading why so few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T06:53:35.943429Z",
     "start_time": "2019-07-09T06:53:33.075541Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:../train.py:Prepare tokenizer, pretrained model and optimizer - add special tokens for fine-tuning\n",
      "INFO:pytorch_pretrained_bert.tokenization_openai:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-vocab.json from cache at /home/wassname/.cache/torch/pytorch_pretrained_bert/4ab93d0cd78ae80e746c27c9cd34e90b470abdabe0590c9ec742df61625ba310.b9628f6fe5519626534b82ce7ec72b22ce0ae79550325f45c604a25c0ad87fd6\n",
      "INFO:pytorch_pretrained_bert.tokenization_openai:loading merges file https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-merges.txt from cache at /home/wassname/.cache/torch/pytorch_pretrained_bert/0f8de0dbd6a2bb6bde7d758f4c120dd6dd20b46f2bf0a47bc899c89f46532fde.20808570f9a3169212a577f819c845330da870aeb14c40f7319819fce10c3b76\n",
      "INFO:pytorch_pretrained_bert.tokenization_openai:Special tokens {'<bos>': 40478, '<eos>': 40479, '<speaker1>': 40480, '<speaker2>': 40481, '<pad>': 40482}\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Prepare tokenizer, pretrained model and optimizer - add special tokens for fine-tuning\")\n",
    "tokenizer_class = GPT2Tokenizer if \"gpt2\" in args.model_checkpoint else OpenAIGPTTokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(args.model_checkpoint)\n",
    "tokenizer.set_special_tokens(SPECIAL_TOKENS)\n",
    "# model.set_num_special_tokens(len(SPECIAL_TOKENS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T07:08:44.131400Z",
     "start_time": "2019-07-09T07:08:02.411233Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 0/1970 [00:00<?, ?file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6muaq4.pickle, pop from empty list\n",
      "WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_83ciax.pickle, pop from empty list\n",
      "train:   2%|▏         | 37/1970 [00:00<00:05, 367.05file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_9r9hpa.pickle, pop from empty list\n",
      "WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6mmanj.pickle, pop from empty list\n",
      "train:   4%|▍         | 75/1970 [00:00<00:05, 369.32file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_79uc7u.pickle, pop from empty list\n",
      "train:   5%|▌         | 105/1970 [00:00<00:05, 343.21file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6onr1n.pickle, pop from empty list\n",
      "train:   9%|▊         | 172/1970 [00:00<00:05, 337.41file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6n2ai9.pickle, pop from empty list\n",
      "train:  10%|█         | 202/1970 [00:00<00:05, 321.10file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6zusq1.pickle, pop from empty list\n",
      "WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_7w3ecb.pickle, pop from empty list\n",
      "train:  13%|█▎        | 257/1970 [00:00<00:06, 252.95file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_82v52g.pickle, pop from empty list\n",
      "WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6nmc6o.pickle, pop from empty list\n",
      "train:  15%|█▍        | 291/1970 [00:00<00:06, 271.92file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6oqgg3.pickle, pop from empty list\n",
      "train:  16%|█▋        | 323/1970 [00:01<00:05, 283.96file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6ouuvt.pickle, pop from empty list\n",
      "train:  20%|█▉        | 389/1970 [00:01<00:05, 299.92file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6mylmz.pickle, pop from empty list\n",
      "train:  21%|██▏       | 422/1970 [00:01<00:05, 307.95file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6owcio.pickle, pop from empty list\n",
      "train:  23%|██▎       | 455/1970 [00:01<00:04, 312.26file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_79qute.pickle, pop from empty list\n",
      "WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6o8gbv.pickle, pop from empty list\n",
      "train:  32%|███▏      | 630/1970 [00:02<00:04, 268.27file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_7jvyym.pickle, pop from empty list\n",
      "train:  35%|███▍      | 687/1970 [00:02<00:04, 261.99file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6ntm2c.pickle, pop from empty list\n",
      "WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6o11ow.pickle, pop from empty list\n",
      "train:  36%|███▌      | 714/1970 [00:02<00:04, 256.34file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_7t8ez9.pickle, pop from empty list\n",
      "train:  38%|███▊      | 740/1970 [00:02<00:04, 257.27file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6mmb7b.pickle, pop from empty list\n",
      "WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6nn8dr.pickle, pop from empty list\n",
      "train:  39%|███▉      | 777/1970 [00:02<00:04, 282.49file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6od3pb.pickle, pop from empty list\n",
      "train:  41%|████      | 807/1970 [00:02<00:04, 278.65file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_9j3ciq.pickle, pop from empty list\n",
      "train:  42%|████▏     | 837/1970 [00:02<00:04, 280.12file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6o3s0c.pickle, pop from empty list\n",
      "train:  47%|████▋     | 926/1970 [00:03<00:03, 262.86file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_9lfb5x.pickle, pop from empty list\n",
      "train:  48%|████▊     | 954/1970 [00:03<00:04, 249.50file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6mjcz4.pickle, pop from empty list\n",
      "WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6n8ydn.pickle, pop from empty list\n",
      "train:  61%|██████    | 1200/1970 [00:04<00:04, 160.13file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/totallynotrobots/t3_8yrj86.pickle, pop from empty list\n",
      "train:  67%|██████▋   | 1321/1970 [00:05<00:03, 179.24file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/totallynotrobots/t3_9tp6nq.pickle, pop from empty list\n",
      "train:  90%|████████▉ | 1771/1970 [00:08<00:01, 152.89file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/totallynotrobots/t3_947zsn.pickle, pop from empty list\n",
      "train: 100%|██████████| 1970/1970 [00:09<00:00, 209.52file/s]\n",
      "valid:   0%|          | 0/221 [00:00<?, ?file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_68tgt2.pickle, pop from empty list\n",
      "valid:  43%|████▎     | 94/221 [00:00<00:00, 308.19file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_7qfftn.pickle, pop from empty list\n",
      "WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_83dfhe.pickle, pop from empty list\n",
      "valid:  86%|████████▌ | 189/221 [00:00<00:00, 213.14file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/totallynotrobots/t3_9zbfqf.pickle, pop from empty list\n",
      "valid:  96%|█████████▌| 212/221 [00:00<00:00, 217.10file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/aww/t3_camn17.pickle, pop from empty list\n",
      "valid: 100%|██████████| 221/221 [00:00<00:00, 226.41file/s]\n",
      "test:   0%|          | 0/245 [00:00<?, ?file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_7ke9qa.pickle, pop from empty list\n",
      "test:  44%|████▎     | 107/245 [00:00<00:00, 354.03file/s]WARNING:../data.py:Exception for file ../data/reddit_threads/singularity/t3_6oqwau.pickle, pop from empty list\n",
      "test: 100%|██████████| 245/245 [00:01<00:00, 235.79file/s]\n",
      "INFO:../data.py:Tokenize and encode the dataset\n"
     ]
    }
   ],
   "source": [
    "personachat = get_dataset(tokenizer, args.dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T08:07:12.517489Z",
     "start_time": "2019-07-09T08:07:09.494565Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-278-e051935154b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpersonachat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_displayhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_output_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_format_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_user_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_exec_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36mcompute_format_data\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m# This can be set to True by the write_output_prompt method in a subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/wassname/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/decorator.py:decorator-gen-10>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreakable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;31m# Special case for 1-item tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreakable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;31m# Special case for 1-item tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreakable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;31m# Special case for 1-item tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreakable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mbreakable\u001b[0;34m(self, sep)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_stack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwant_break\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/jup3.7.2/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;34m\"\"\"Flush data that is left in the buffer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_width\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "personachat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T07:10:23.051924Z",
     "start_time": "2019-07-09T07:10:22.871879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[220, 117, 67],\n",
       " [78, 43, 35],\n",
       " [39, 98, 75],\n",
       " [37, 112, 86],\n",
       " [107, 40, 80],\n",
       " [112, 308, 55],\n",
       " [58, 48, 44],\n",
       " [100, 28, 98],\n",
       " [38, 41, 333],\n",
       " [42, 35, 45],\n",
       " [39, 72, 44],\n",
       " [68, 72, 85],\n",
       " [36, 51, 56],\n",
       " [119, 71, 50],\n",
       " [42, 119, 73],\n",
       " [136, 70, 34],\n",
       " [59, 212, 26],\n",
       " [503, 209, 206],\n",
       " [92, 90, 79],\n",
       " [37, 25, 272],\n",
       " [75, 330, 68],\n",
       " [41, 40, 512],\n",
       " [49, 69, 75],\n",
       " [64, 73, 29],\n",
       " [90, 129, 36],\n",
       " [55, 141, 28],\n",
       " [37, 66, 126],\n",
       " [46, 34, 110],\n",
       " [76, 35, 26],\n",
       " [46, 27, 37],\n",
       " [43, 33, 34],\n",
       " [49, 105, 56],\n",
       " [91, 82, 80],\n",
       " [70, 34, 35],\n",
       " [82, 77, 151],\n",
       " [316, 28, 28],\n",
       " [512, 35, 61],\n",
       " [34, 50, 36],\n",
       " [121, 154, 49],\n",
       " [46, 114, 31],\n",
       " [207, 48, 116],\n",
       " [83, 37, 40],\n",
       " [121, 139, 24],\n",
       " [42, 41, 288],\n",
       " [50, 29, 26],\n",
       " [119, 103, 145],\n",
       " [54, 39, 50],\n",
       " [40, 94, 80],\n",
       " [40, 32, 69],\n",
       " [40, 62, 49],\n",
       " [64, 30, 26],\n",
       " [92, 34, 31],\n",
       " [132, 31, 32],\n",
       " [71, 51, 64],\n",
       " [101, 99, 98],\n",
       " [142, 64, 150],\n",
       " [152, 97, 282],\n",
       " [122, 193, 64],\n",
       " [263, 94, 49],\n",
       " [177, 52, 69],\n",
       " [51, 139, 107],\n",
       " [58, 50, 51],\n",
       " [60, 69, 27],\n",
       " [108, 110, 94],\n",
       " [87, 211, 106],\n",
       " [218, 85, 460],\n",
       " [129, 145, 63],\n",
       " [365, 76, 83],\n",
       " [133, 32, 46],\n",
       " [46, 45, 56],\n",
       " [103, 63, 35],\n",
       " [32, 60, 28],\n",
       " [141, 49, 49],\n",
       " [38, 85, 32],\n",
       " [220, 89, 65],\n",
       " [46, 57, 170],\n",
       " [73, 91, 63],\n",
       " [36, 48, 59],\n",
       " [81, 69, 157],\n",
       " [178, 73, 88],\n",
       " [362, 37, 87],\n",
       " [120, 61, 67],\n",
       " [35, 66, 38],\n",
       " [100, 39, 104],\n",
       " [118, 62, 139],\n",
       " [28, 30, 32],\n",
       " [62, 33, 45],\n",
       " [58, 394, 100],\n",
       " [207, 207, 42],\n",
       " [34, 46, 110],\n",
       " [140, 132, 279],\n",
       " [77, 52, 41],\n",
       " [36, 35, 76],\n",
       " [180, 181, 162],\n",
       " [33, 33, 26],\n",
       " [140, 91, 36],\n",
       " [41, 53, 84],\n",
       " [90, 124, 45],\n",
       " [174, 71, 84],\n",
       " [42, 31, 51],\n",
       " [62, 76, 297],\n",
       " [44, 84, 32],\n",
       " [32, 28, 29],\n",
       " [67, 62, 49],\n",
       " [75, 58, 52],\n",
       " [46, 26, 43],\n",
       " [55, 55, 119],\n",
       " [106, 166, 180],\n",
       " [26, 75, 28],\n",
       " [44, 24, 25],\n",
       " [48, 263, 45],\n",
       " [71, 57, 29],\n",
       " [154, 90, 67],\n",
       " [61, 77, 34],\n",
       " [41, 104, 105],\n",
       " [36, 33, 29],\n",
       " [50, 93, 35],\n",
       " [170, 71, 90],\n",
       " [169, 59, 142],\n",
       " [51, 44, 32],\n",
       " [62, 28, 78],\n",
       " [33, 45, 39],\n",
       " [39, 33, 272],\n",
       " [40, 52, 55],\n",
       " [58, 106, 41],\n",
       " [103, 106, 179],\n",
       " [28, 90, 99],\n",
       " [54, 43, 86],\n",
       " [32, 32, 84],\n",
       " [85, 56, 56],\n",
       " [32, 24, 31],\n",
       " [67, 24, 38],\n",
       " [53, 161, 278],\n",
       " [53, 51, 141],\n",
       " [34, 148, 29],\n",
       " [92, 52, 31],\n",
       " [43, 77, 71],\n",
       " [202, 63, 61],\n",
       " [45, 63, 32],\n",
       " [104, 86, 34],\n",
       " [71, 50, 138],\n",
       " [56, 225, 55],\n",
       " [37, 135, 75],\n",
       " [39, 39, 62],\n",
       " [57, 25, 65],\n",
       " [35, 49, 44],\n",
       " [30, 67, 31],\n",
       " [47, 151, 56],\n",
       " [98, 99, 42],\n",
       " [96, 232, 65],\n",
       " [72, 66, 279],\n",
       " [63, 283, 74],\n",
       " [114, 38, 512],\n",
       " [56, 27, 90],\n",
       " [29, 31, 52],\n",
       " [62, 41, 43],\n",
       " [120, 48, 61],\n",
       " [45, 42, 33],\n",
       " [24, 25, 24],\n",
       " [49, 75, 26],\n",
       " [85, 97, 73],\n",
       " [46, 140, 175],\n",
       " [120, 146, 57],\n",
       " [40, 34, 85],\n",
       " [40, 30, 67],\n",
       " [90, 100, 36],\n",
       " [33, 23, 27],\n",
       " [40, 120, 220],\n",
       " [31, 96, 132],\n",
       " [65, 190, 188],\n",
       " [56, 30, 301],\n",
       " [161, 33, 214],\n",
       " [147, 54, 110],\n",
       " [65, 30, 43],\n",
       " [157, 156, 156],\n",
       " [103, 47, 258],\n",
       " [83, 107, 71],\n",
       " [91, 235, 179],\n",
       " [34, 56, 99],\n",
       " [32, 53, 37],\n",
       " [29, 80, 26],\n",
       " [52, 57, 55],\n",
       " [63, 32, 27],\n",
       " [35, 42, 34],\n",
       " [36, 27, 31],\n",
       " [62, 306, 31],\n",
       " [128, 66, 87],\n",
       " [44, 33, 60],\n",
       " [88, 202, 134],\n",
       " [104, 99, 119],\n",
       " [159, 45, 104],\n",
       " [98, 35, 58],\n",
       " [50, 44, 29],\n",
       " [66, 97, 88],\n",
       " [55, 110, 73],\n",
       " [73, 71, 135],\n",
       " [46, 128, 199],\n",
       " [59, 81, 151],\n",
       " [73, 95, 35],\n",
       " [134, 28, 292],\n",
       " [41, 86, 133],\n",
       " [138, 59, 122],\n",
       " [325, 75, 167],\n",
       " [134, 121, 70],\n",
       " [129, 50, 43],\n",
       " [144, 58, 29],\n",
       " [43, 62, 27],\n",
       " [63, 40, 28],\n",
       " [35, 50, 28],\n",
       " [142, 242, 106],\n",
       " [86, 48, 63],\n",
       " [42, 58, 136],\n",
       " [30, 64, 81],\n",
       " [189, 64, 43],\n",
       " [70, 28, 79],\n",
       " [66, 77, 51],\n",
       " [127, 128, 117],\n",
       " [192, 101, 66],\n",
       " [89, 43, 28],\n",
       " [56, 26, 43],\n",
       " [52, 65, 80],\n",
       " [83, 39, 83],\n",
       " [29, 46, 33],\n",
       " [81, 54, 186],\n",
       " [127, 317, 47],\n",
       " [51, 228, 163],\n",
       " [254, 200, 183],\n",
       " [512, 54, 57],\n",
       " [321, 181, 350],\n",
       " [55, 43, 45],\n",
       " [33, 55, 136],\n",
       " [111, 110, 31],\n",
       " [36, 71, 45],\n",
       " [28, 140, 37],\n",
       " [205, 51, 61],\n",
       " [110, 58, 60],\n",
       " [94, 159, 60],\n",
       " [42, 32, 32],\n",
       " [81, 306, 220],\n",
       " [130, 44, 141],\n",
       " [76, 39, 35],\n",
       " [60, 67, 137],\n",
       " [32, 41, 33],\n",
       " [38, 71, 73],\n",
       " [36, 35, 38],\n",
       " [50, 44, 49],\n",
       " [80, 87, 108],\n",
       " [102, 72, 77],\n",
       " [512, 80, 205],\n",
       " [90, 156, 75],\n",
       " [65, 188, 100],\n",
       " [93, 335, 103],\n",
       " [68, 158, 88],\n",
       " [46, 81, 97],\n",
       " [83, 60, 41],\n",
       " [199, 60, 103],\n",
       " [54, 81, 34],\n",
       " [173, 82, 106],\n",
       " [77, 68, 117],\n",
       " [55, 34, 49],\n",
       " [114, 311, 56],\n",
       " [125, 49, 31],\n",
       " [39, 43, 51],\n",
       " [61, 43, 29],\n",
       " [37, 184, 183],\n",
       " [86, 36, 85],\n",
       " [81, 27, 51],\n",
       " [90, 324, 51],\n",
       " [35, 117, 54],\n",
       " [42, 44, 66],\n",
       " [57, 56, 28],\n",
       " [487, 167, 360],\n",
       " [85, 61, 37],\n",
       " [67, 56, 39],\n",
       " [50, 62, 51],\n",
       " [41, 334, 47],\n",
       " [24, 38, 104],\n",
       " [50, 138, 90],\n",
       " [230, 208, 57],\n",
       " [44, 179, 214],\n",
       " [88, 44, 402],\n",
       " [97, 56, 46],\n",
       " [58, 37, 36],\n",
       " [40, 45, 38],\n",
       " [33, 192, 54],\n",
       " [52, 109, 39],\n",
       " [47, 54, 49],\n",
       " [72, 58, 74],\n",
       " [50, 117, 66],\n",
       " [188, 47, 63],\n",
       " [74, 46, 54],\n",
       " [196, 35, 68],\n",
       " [170, 63, 44],\n",
       " [39, 39, 77],\n",
       " [34, 99, 53],\n",
       " [45, 71, 88],\n",
       " [61, 113, 99],\n",
       " [121, 37, 92],\n",
       " [77, 36, 28],\n",
       " [183, 353, 156],\n",
       " [38, 59, 73],\n",
       " [54, 233, 88],\n",
       " [55, 41, 38],\n",
       " [37, 49, 45],\n",
       " [512, 196, 96],\n",
       " [29, 75, 35],\n",
       " [83, 78, 120],\n",
       " [51, 49, 39],\n",
       " [77, 47, 47],\n",
       " [512, 89, 176],\n",
       " [88, 233, 512],\n",
       " [81, 75, 37],\n",
       " [33, 223, 35],\n",
       " [35, 57, 170],\n",
       " [39, 50, 83],\n",
       " [95, 54, 55],\n",
       " [91, 60, 33],\n",
       " [99, 364, 67],\n",
       " [97, 182, 37],\n",
       " [79, 65, 91],\n",
       " [104, 38, 66],\n",
       " [82, 150, 184],\n",
       " [42, 61, 25],\n",
       " [43, 117, 45],\n",
       " [47, 34, 36],\n",
       " [40, 52, 38],\n",
       " [163, 57, 102],\n",
       " [151, 144, 83],\n",
       " [95, 136, 96],\n",
       " [96, 49, 402],\n",
       " [25, 58, 31],\n",
       " [34, 28, 46],\n",
       " [57, 415, 426],\n",
       " [34, 56, 87],\n",
       " [104, 140, 70],\n",
       " [62, 31, 59],\n",
       " [80, 42, 31],\n",
       " [42, 43, 72],\n",
       " [44, 39, 40],\n",
       " [69, 223, 49],\n",
       " [81, 30, 71],\n",
       " [62, 34, 25],\n",
       " [36, 191, 206],\n",
       " [57, 43, 43],\n",
       " [104, 74, 78],\n",
       " [27, 48, 55],\n",
       " [54, 45, 29],\n",
       " [193, 132, 53],\n",
       " [26, 33, 170],\n",
       " [70, 111, 76],\n",
       " [68, 41, 129],\n",
       " [42, 98, 45],\n",
       " [36, 102, 117],\n",
       " [138, 49, 45],\n",
       " [229, 252, 29],\n",
       " [48, 30, 73],\n",
       " [30, 59, 31],\n",
       " [106, 155, 24],\n",
       " [89, 73, 94],\n",
       " [90, 53, 119],\n",
       " [45, 87, 30],\n",
       " [33, 41, 30],\n",
       " [42, 33, 55],\n",
       " [69, 160, 58],\n",
       " [123, 111, 41],\n",
       " [150, 46, 24],\n",
       " [152, 110, 464],\n",
       " [64, 165, 105],\n",
       " [73, 39, 64],\n",
       " [82, 50, 37],\n",
       " [74, 102, 29],\n",
       " [115, 66, 63],\n",
       " [42, 43, 82],\n",
       " [81, 44, 43],\n",
       " [62, 41, 27],\n",
       " [104, 32, 65],\n",
       " [74, 35, 80],\n",
       " [94, 50, 52],\n",
       " [69, 37, 83],\n",
       " [62, 38, 31],\n",
       " [40, 31, 264],\n",
       " [83, 52, 392],\n",
       " [68, 192, 512],\n",
       " [54, 45, 44],\n",
       " [48, 33, 33],\n",
       " [139, 93, 42],\n",
       " [116, 76, 145],\n",
       " [41, 30, 35],\n",
       " [76, 28, 31],\n",
       " [26, 58, 176],\n",
       " [55, 58, 37],\n",
       " [88, 37, 32],\n",
       " [66, 41, 66],\n",
       " [35, 49, 56],\n",
       " [81, 43, 39],\n",
       " [60, 55, 82],\n",
       " [85, 32, 37],\n",
       " [63, 60, 60],\n",
       " [42, 77, 153],\n",
       " [164, 67, 166],\n",
       " [128, 34, 53],\n",
       " [146, 78, 40],\n",
       " [252, 50, 176],\n",
       " [35, 67, 33],\n",
       " [62, 33, 60],\n",
       " [47, 31, 33],\n",
       " [53, 118, 60],\n",
       " [178, 89, 35],\n",
       " [76, 106, 33],\n",
       " [50, 40, 31],\n",
       " [97, 139, 38],\n",
       " [100, 27, 181],\n",
       " [91, 139, 27],\n",
       " [65, 105, 41],\n",
       " [69, 72, 123],\n",
       " [50, 196, 207],\n",
       " [60, 38, 303],\n",
       " [34, 41, 165],\n",
       " [74, 77, 40],\n",
       " [65, 119, 45],\n",
       " [58, 41, 45],\n",
       " [134, 29, 86],\n",
       " [34, 60, 44],\n",
       " [67, 512, 54],\n",
       " [264, 268, 146],\n",
       " [101, 47, 63],\n",
       " [34, 512, 77],\n",
       " [184, 412, 85],\n",
       " [65, 54, 27],\n",
       " [45, 27, 35],\n",
       " [81, 45, 193],\n",
       " [57, 33, 46],\n",
       " [98, 235, 115],\n",
       " [165, 36, 31],\n",
       " [27, 74, 40],\n",
       " [35, 43, 62],\n",
       " [42, 60, 58],\n",
       " [48, 51, 41],\n",
       " [58, 37, 80],\n",
       " [92, 115, 92],\n",
       " [98, 158, 58],\n",
       " [92, 183, 99],\n",
       " [26, 79, 31],\n",
       " [152, 101, 118],\n",
       " [63, 106, 134],\n",
       " [129, 67, 172],\n",
       " [249, 47, 93],\n",
       " [114, 109, 64],\n",
       " [43, 29, 306],\n",
       " [38, 49, 84],\n",
       " [119, 38, 64],\n",
       " [52, 47, 48],\n",
       " [58, 180, 35],\n",
       " [136, 47, 80],\n",
       " [40, 75, 36],\n",
       " [84, 33, 33],\n",
       " [56, 71, 44],\n",
       " [56, 45, 43],\n",
       " [48, 43, 35],\n",
       " [57, 83, 64],\n",
       " [295, 95, 43],\n",
       " [48, 87, 37],\n",
       " [80, 183, 31],\n",
       " [130, 119, 32],\n",
       " [60, 37, 40],\n",
       " [117, 58, 79],\n",
       " [52, 48, 30],\n",
       " [33, 51, 28],\n",
       " [133, 31, 38],\n",
       " [55, 45, 80],\n",
       " [27, 35, 28],\n",
       " [60, 122, 71],\n",
       " [63, 34, 31],\n",
       " [165, 50, 84],\n",
       " [41, 39, 37],\n",
       " [67, 55, 35],\n",
       " [32, 49, 29],\n",
       " [33, 58, 36],\n",
       " [89, 50, 37],\n",
       " [196, 47, 79],\n",
       " [198, 23, 68],\n",
       " [68, 108, 65],\n",
       " [26, 49, 46],\n",
       " [68, 49, 204],\n",
       " [280, 154, 60],\n",
       " [61, 116, 79],\n",
       " [58, 36, 85],\n",
       " [40, 75, 37],\n",
       " [175, 36, 220],\n",
       " [66, 47, 55],\n",
       " [120, 62, 36],\n",
       " [53, 130, 26],\n",
       " [42, 142, 39],\n",
       " [24, 24, 24],\n",
       " [87, 77, 28],\n",
       " [49, 39, 31],\n",
       " [33, 104, 33],\n",
       " [72, 94, 74],\n",
       " [512, 290, 119],\n",
       " [78, 37, 127],\n",
       " [297, 112, 251],\n",
       " [43, 40, 157],\n",
       " [89, 77, 24],\n",
       " [74, 114, 56],\n",
       " [71, 90, 40],\n",
       " [128, 60, 75],\n",
       " [58, 41, 52],\n",
       " [183, 101, 31],\n",
       " [71, 118, 83],\n",
       " [104, 97, 54],\n",
       " [51, 43, 96],\n",
       " [57, 33, 34],\n",
       " [40, 29, 45],\n",
       " [134, 232, 106],\n",
       " [141, 31, 95],\n",
       " [46, 40, 39],\n",
       " [61, 112, 109],\n",
       " [44, 72, 31],\n",
       " [72, 34, 52],\n",
       " [33, 44, 60],\n",
       " [137, 75, 76],\n",
       " [200, 111, 90],\n",
       " [39, 87, 124],\n",
       " [100, 101, 100],\n",
       " [181, 125, 75],\n",
       " [60, 83, 65],\n",
       " [343, 92, 184],\n",
       " [47, 59, 25],\n",
       " [79, 136, 97],\n",
       " [35, 28, 34],\n",
       " [119, 59, 86],\n",
       " [62, 64, 55],\n",
       " [94, 58, 36],\n",
       " [68, 176, 30],\n",
       " [116, 274, 273],\n",
       " [93, 41, 86],\n",
       " [96, 36, 183],\n",
       " [61, 257, 80],\n",
       " [34, 78, 70],\n",
       " [69, 32, 66],\n",
       " [192, 283, 512],\n",
       " [36, 46, 145],\n",
       " [56, 49, 46],\n",
       " [112, 26, 34],\n",
       " [62, 347, 37],\n",
       " [98, 110, 49],\n",
       " [54, 255, 92],\n",
       " [114, 164, 36],\n",
       " [112, 133, 60],\n",
       " [139, 42, 164],\n",
       " [62, 119, 92],\n",
       " [95, 75, 99],\n",
       " [45, 39, 81],\n",
       " [34, 44, 57],\n",
       " [92, 43, 71],\n",
       " [50, 81, 31],\n",
       " [181, 132, 71],\n",
       " [254, 207, 79],\n",
       " [409, 89, 262],\n",
       " [136, 120, 51],\n",
       " [103, 77, 439],\n",
       " [33, 38, 57],\n",
       " [53, 68, 308],\n",
       " [512, 512, 512],\n",
       " [50, 27, 53],\n",
       " [67, 93, 59],\n",
       " [49, 37, 219],\n",
       " [43, 30, 22],\n",
       " [151, 60, 32],\n",
       " [141, 187, 50],\n",
       " [34, 92, 436],\n",
       " [80, 66, 53],\n",
       " [128, 139, 31],\n",
       " [43, 57, 33],\n",
       " [51, 34, 59],\n",
       " [62, 52, 71],\n",
       " [43, 53, 43],\n",
       " [59, 236, 69],\n",
       " [27, 34, 33],\n",
       " [47, 36, 27],\n",
       " [118, 88, 63],\n",
       " [103, 44, 41],\n",
       " [117, 61, 61],\n",
       " [32, 30, 41],\n",
       " [116, 32, 43],\n",
       " [42, 76, 119],\n",
       " [116, 83, 47],\n",
       " [58, 324, 41],\n",
       " [49, 51, 41],\n",
       " [42, 25, 178],\n",
       " [47, 30, 28],\n",
       " [115, 50, 321],\n",
       " [45, 59, 63],\n",
       " [66, 68, 41],\n",
       " [131, 63, 111],\n",
       " [133, 111, 128],\n",
       " [249, 41, 40],\n",
       " [118, 126, 110],\n",
       " [61, 166, 65],\n",
       " [88, 35, 32],\n",
       " [97, 40, 69],\n",
       " [180, 62, 23],\n",
       " [35, 29, 185],\n",
       " [92, 54, 139],\n",
       " [124, 60, 142],\n",
       " [106, 63, 37],\n",
       " [169, 82, 195],\n",
       " [44, 85, 82],\n",
       " [65, 82, 78],\n",
       " [82, 70, 236],\n",
       " [55, 60, 77],\n",
       " [86, 54, 48],\n",
       " [52, 64, 40],\n",
       " [48, 33, 99],\n",
       " [96, 47, 44],\n",
       " [68, 88, 27],\n",
       " [157, 33, 26],\n",
       " [91, 252, 35],\n",
       " [119, 147, 83],\n",
       " [78, 32, 53],\n",
       " [209, 48, 35],\n",
       " [77, 67, 156],\n",
       " [39, 56, 34],\n",
       " [46, 57, 41],\n",
       " [146, 57, 76],\n",
       " [41, 46, 32],\n",
       " [73, 50, 48],\n",
       " [27, 41, 32],\n",
       " [28, 239, 73],\n",
       " [30, 136, 97],\n",
       " [49, 68, 37],\n",
       " [43, 71, 115],\n",
       " [99, 86, 165],\n",
       " [124, 53, 73],\n",
       " [158, 165, 120],\n",
       " [279, 44, 144],\n",
       " [26, 49, 32],\n",
       " [63, 70, 114],\n",
       " [56, 142, 100],\n",
       " [35, 36, 82],\n",
       " [127, 133, 59],\n",
       " [46, 56, 90],\n",
       " [47, 235, 118],\n",
       " [90, 45, 169],\n",
       " [111, 41, 40],\n",
       " [84, 81, 56],\n",
       " [139, 139, 47],\n",
       " [40, 74, 69],\n",
       " [45, 26, 24],\n",
       " [31, 31, 46],\n",
       " [55, 53, 42],\n",
       " [28, 64, 50],\n",
       " [58, 59, 37],\n",
       " [25, 123, 50],\n",
       " [60, 39, 35],\n",
       " [32, 98, 76],\n",
       " [178, 209, 41],\n",
       " [177, 44, 157],\n",
       " [81, 72, 75],\n",
       " [67, 59, 82],\n",
       " [47, 41, 68],\n",
       " [34, 41, 33],\n",
       " [58, 91, 85],\n",
       " [76, 143, 132],\n",
       " [129, 83, 264],\n",
       " [126, 71, 156],\n",
       " [42, 39, 109],\n",
       " [85, 43, 90],\n",
       " [40, 67, 38],\n",
       " [134, 48, 105],\n",
       " [61, 30, 98],\n",
       " [83, 54, 34],\n",
       " [102, 101, 103],\n",
       " [111, 38, 110],\n",
       " [72, 47, 30],\n",
       " [37, 65, 189],\n",
       " [35, 37, 41],\n",
       " [56, 24, 33],\n",
       " [80, 37, 59],\n",
       " [32, 30, 27],\n",
       " [188, 65, 196],\n",
       " [56, 126, 91],\n",
       " [201, 103, 186],\n",
       " [108, 87, 101],\n",
       " [65, 59, 25],\n",
       " [57, 92, 52],\n",
       " [59, 84, 53],\n",
       " [38, 93, 38],\n",
       " [269, 52, 40],\n",
       " [165, 42, 51],\n",
       " [67, 108, 32],\n",
       " [67, 39, 93],\n",
       " [187, 82, 96],\n",
       " [98, 46, 37],\n",
       " [54, 42, 24],\n",
       " [72, 36, 123],\n",
       " [30, 63, 48],\n",
       " [55, 28, 39],\n",
       " [68, 49, 41],\n",
       " [92, 40, 49],\n",
       " [30, 42, 38],\n",
       " [83, 69, 81],\n",
       " [34, 38, 48],\n",
       " [35, 252, 74],\n",
       " [82, 67, 230],\n",
       " [70, 42, 80],\n",
       " [34, 32, 34],\n",
       " [32, 34, 45],\n",
       " [135, 28, 43],\n",
       " [50, 51, 60],\n",
       " [104, 59, 69],\n",
       " [316, 36, 38],\n",
       " [193, 49, 99],\n",
       " [37, 376, 62],\n",
       " [64, 90, 33],\n",
       " [441, 43, 38],\n",
       " [93, 95, 59],\n",
       " [56, 116, 175],\n",
       " [158, 82, 43],\n",
       " [52, 77, 222],\n",
       " [87, 80, 218],\n",
       " [30, 45, 48],\n",
       " [46, 52, 44],\n",
       " [50, 109, 71],\n",
       " [145, 100, 94],\n",
       " [83, 41, 37],\n",
       " [81, 71, 95],\n",
       " [51, 26, 79],\n",
       " [145, 63, 60],\n",
       " [83, 51, 112],\n",
       " [38, 228, 26],\n",
       " [30, 64, 45],\n",
       " [55, 40, 47],\n",
       " [39, 172, 105],\n",
       " [140, 512, 146],\n",
       " [177, 114, 35],\n",
       " [103, 93, 38],\n",
       " [44, 95, 79],\n",
       " [30, 47, 50],\n",
       " [30, 27, 26],\n",
       " [34, 194, 123],\n",
       " [55, 205, 77],\n",
       " [42, 45, 123],\n",
       " [109, 57, 52],\n",
       " [77, 69, 73],\n",
       " [99, 135, 154],\n",
       " [84, 52, 46],\n",
       " [29, 48, 26],\n",
       " [39, 53, 436],\n",
       " [46, 32, 59],\n",
       " [25, 139, 98],\n",
       " [26, 40, 43],\n",
       " [60, 59, 107],\n",
       " [142, 94, 100],\n",
       " [28, 27, 26],\n",
       " [81, 48, 179],\n",
       " [38, 72, 46],\n",
       " [27, 79, 27],\n",
       " [25, 50, 28],\n",
       " [94, 120, 76],\n",
       " [60, 37, 77],\n",
       " [35, 30, 76],\n",
       " [145, 30, 44],\n",
       " [93, 99, 42],\n",
       " [86, 218, 47],\n",
       " [68, 48, 52],\n",
       " [110, 143, 45],\n",
       " [108, 59, 90],\n",
       " [47, 37, 130],\n",
       " [52, 84, 51],\n",
       " [53, 62, 35],\n",
       " [32, 33, 62],\n",
       " [32, 42, 27],\n",
       " [100, 86, 46],\n",
       " [220, 42, 93],\n",
       " [87, 243, 84],\n",
       " [133, 55, 95],\n",
       " [151, 67, 34],\n",
       " [345, 34, 246],\n",
       " [208, 112, 85],\n",
       " [34, 27, 47],\n",
       " [33, 48, 512],\n",
       " [35, 318, 73],\n",
       " [107, 26, 31],\n",
       " [41, 78, 38],\n",
       " [27, 27, 136],\n",
       " [73, 145, 69],\n",
       " [399, 183, 164],\n",
       " [32, 79, 79],\n",
       " [46, 156, 36],\n",
       " [142, 81, 185],\n",
       " [64, 47, 101],\n",
       " [140, 123, 140],\n",
       " [46, 58, 75],\n",
       " [68, 32, 93],\n",
       " [30, 28, 30],\n",
       " [100, 62, 133],\n",
       " [73, 42, 54],\n",
       " [119, 28, 63],\n",
       " [27, 153, 29],\n",
       " [105, 75, 32],\n",
       " [91, 53, 166],\n",
       " [48, 111, 36],\n",
       " [67, 74, 28],\n",
       " [36, 34, 87],\n",
       " [51, 43, 43],\n",
       " [49, 34, 78],\n",
       " [26, 153, 70],\n",
       " [245, 55, 74],\n",
       " [82, 45, 33],\n",
       " [56, 46, 33],\n",
       " [67, 29, 45],\n",
       " [62, 58, 36],\n",
       " [57, 243, 182],\n",
       " [34, 34, 68],\n",
       " [52, 101, 77],\n",
       " [49, 180, 30],\n",
       " [510, 154, 77],\n",
       " [211, 78, 512],\n",
       " [58, 40, 368],\n",
       " [512, 431, 512],\n",
       " [35, 222, 27],\n",
       " [38, 86, 57],\n",
       " [60, 38, 35],\n",
       " [111, 37, 42],\n",
       " [50, 43, 43],\n",
       " [161, 100, 200],\n",
       " [131, 101, 110],\n",
       " [134, 61, 190],\n",
       " [45, 56, 133],\n",
       " [50, 172, 35],\n",
       " [33, 47, 29],\n",
       " [33, 52, 53],\n",
       " [83, 344, 377],\n",
       " [45, 65, 27],\n",
       " [82, 79, 54],\n",
       " [52, 30, 30],\n",
       " [30, 88, 86],\n",
       " [28, 46, 42],\n",
       " [52, 28, 39],\n",
       " [113, 28, 31],\n",
       " [84, 134, 66],\n",
       " [413, 66, 102],\n",
       " [97, 49, 35],\n",
       " [91, 42, 39],\n",
       " [60, 63, 74],\n",
       " [42, 32, 39],\n",
       " [72, 54, 93],\n",
       " [74, 86, 46],\n",
       " [24, 188, 57],\n",
       " [55, 92, 32],\n",
       " [233, 59, 30],\n",
       " [117, 164, 281],\n",
       " [66, 84, 42],\n",
       " [61, 45, 28],\n",
       " [83, 84, 83],\n",
       " [39, 40, 37],\n",
       " [40, 27, 120],\n",
       " [77, 28, 43],\n",
       " [38, 33, 128],\n",
       " [87, 48, 42],\n",
       " [33, 76, 79],\n",
       " [105, 45, 133],\n",
       " [68, 82, 32],\n",
       " [35, 28, 41],\n",
       " [64, 175, 31],\n",
       " [79, 133, 203],\n",
       " [62, 101, 32],\n",
       " [28, 28, 41],\n",
       " [54, 206, 75],\n",
       " [146, 154, 344],\n",
       " [81, 45, 90],\n",
       " [71, 44, 162],\n",
       " [142, 100, 31],\n",
       " [92, 83, 255],\n",
       " [73, 30, 360],\n",
       " [196, 130, 177],\n",
       " [105, 74, 190],\n",
       " [115, 87, 178],\n",
       " [86, 40, 73],\n",
       " [78, 57, 43],\n",
       " [129, 116, 31],\n",
       " [43, 172, 135],\n",
       " [44, 65, 96],\n",
       " [32, 88, 81],\n",
       " [86, 29, 34],\n",
       " [53, 114, 150],\n",
       " [126, 36, 112],\n",
       " [90, 85, 59],\n",
       " [420, 155, 137],\n",
       " [154, 45, 56],\n",
       " [58, 43, 29],\n",
       " [32, 48, 36],\n",
       " [57, 131, 69],\n",
       " [42, 80, 101],\n",
       " [47, 28, 40],\n",
       " [72, 143, 51],\n",
       " [154, 86, 83],\n",
       " [56, 82, 46],\n",
       " [167, 28, 64],\n",
       " [131, 50, 81],\n",
       " [36, 44, 29],\n",
       " [512, 94, 120],\n",
       " [36, 34, 54],\n",
       " [40, 32, 49],\n",
       " [48, 97, 40],\n",
       " [85, 88, 64],\n",
       " [27, 55, 42],\n",
       " [93, 208, 86],\n",
       " [162, 87, 44],\n",
       " [45, 34, 43],\n",
       " [42, 71, 52],\n",
       " [30, 32, 25],\n",
       " [98, 42, 65],\n",
       " [117, 36, 148],\n",
       " [76, 38, 62],\n",
       " [315, 512, 117],\n",
       " [176, 41, 70],\n",
       " [30, 147, 89],\n",
       " [68, 44, 85],\n",
       " [28, 42, 53],\n",
       " [79, 32, 36],\n",
       " [64, 71, 46],\n",
       " [70, 118, 47],\n",
       " [51, 62, 183],\n",
       " [83, 25, 57],\n",
       " [89, 279, 81],\n",
       " [45, 50, 74],\n",
       " [31, 41, 45],\n",
       " [76, 133, 51],\n",
       " [42, 76, 48],\n",
       " [68, 63, 60],\n",
       " [38, 39, 144],\n",
       " [118, 416, 84],\n",
       " [59, 26, 24],\n",
       " [173, 35, 49],\n",
       " [49, 92, 59],\n",
       " [43, 91, 56],\n",
       " [84, 54, 52],\n",
       " [44, 104, 40],\n",
       " [46, 99, 27],\n",
       " [82, 41, 50],\n",
       " [126, 92, 55],\n",
       " [54, 72, 75],\n",
       " [268, 44, 66],\n",
       " [129, 31, 30],\n",
       " [151, 62, 26],\n",
       " [83, 37, 36],\n",
       " [37, 51, 78],\n",
       " [71, 96, 21],\n",
       " [36, 65, 261],\n",
       " [43, 34, 47],\n",
       " [31, 57, 68],\n",
       " [54, 85, 68],\n",
       " [127, 78, 98],\n",
       " [54, 41, 117],\n",
       " [36, 44, 35],\n",
       " [55, 33, 42],\n",
       " [57, 30, 49],\n",
       " [56, 75, 36],\n",
       " [44, 56, 126],\n",
       " [55, 74, 50],\n",
       " [46, 80, 68],\n",
       " [30, 39, 35],\n",
       " [64, 35, 169],\n",
       " [52, 44, 69],\n",
       " [92, 52, 73],\n",
       " [27, 96, 30],\n",
       " [70, 59, 207],\n",
       " [77, 50, 202],\n",
       " [40, 46, 34],\n",
       " [27, 90, 103],\n",
       " [31, 30, 63],\n",
       " [70, 69, 197],\n",
       " [34, 33, 25],\n",
       " [79, 31, 70],\n",
       " [39, 68, 165],\n",
       " [73, 47, 32],\n",
       " [49, 87, 43],\n",
       " [53, 79, 36],\n",
       " [89, 152, 59],\n",
       " [164, 36, 40],\n",
       " [107, 42, 108],\n",
       " [31, 324, 52]]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[len(s) for s in c['candidates']] for c in utterances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T07:25:29.148989Z",
     "start_time": "2019-07-09T07:25:29.046660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterances = personachat['train'][0]['utterances']\n",
    "[len(c['candidates']) for c in utterances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T07:25:38.852367Z",
     "start_time": "2019-07-09T07:25:38.721609Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:../train.py:Build inputs and labels\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "input should be less than max len",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-221-405f2aa350a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutterance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"candidates\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnum_candidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mlm_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_candidates\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                     \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_input_from_segments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersona\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_array\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                         \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/wassname/Storage5/projects2/thinkcd/transfer-learning-conv-ai/train.py\u001b[0m in \u001b[0;36mbuild_input_from_segments\u001b[0;34m(persona, history, reply, tokenizer, lm_labels, with_eos)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlm_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lm_labels\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input should be less than max len'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: input should be less than max len"
     ]
    }
   ],
   "source": [
    "logger.info(\"Build inputs and labels\")\n",
    "datasets = {\"train\": defaultdict(list), \"valid\": defaultdict(list), \"test\": defaultdict(list)}\n",
    "for dataset_name, dataset in personachat.items():\n",
    "    num_candidates = len(dataset[0][\"utterances\"][0][\"candidates\"])\n",
    "    if args.num_candidates > 0 and dataset_name == 'train':\n",
    "        num_candidates = min(args.num_candidates, num_candidates)\n",
    "    for dialog in dataset:\n",
    "        persona = dialog[\"personality\"].copy()\n",
    "        for _ in range(args.personality_permutations):\n",
    "            for utterance in dialog[\"utterances\"]:\n",
    "                history = utterance[\"history\"][-(2*args.max_history+1):]\n",
    "                for j, candidate in enumerate(utterance[\"candidates\"][-num_candidates:]):\n",
    "                    lm_labels = bool(j == num_candidates-1)\n",
    "                    instance, _ = build_input_from_segments(persona, history, candidate, tokenizer, lm_labels)\n",
    "                    for input_name, input_array in instance.items():\n",
    "                        datasets[dataset_name][input_name].append(input_array)\n",
    "                datasets[dataset_name][\"mc_labels\"].append(num_candidates - 1)\n",
    "                datasets[dataset_name][\"n_candidates\"] = num_candidates\n",
    "            persona = [persona[-1]] + persona[:-1]  # permuted personalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T07:31:27.005464Z",
     "start_time": "2019-07-09T07:31:26.877080Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:../train.py:Build inputs and labels\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Build inputs and labels\")\n",
    "datasets = {\"train\": defaultdict(list), \"valid\": defaultdict(list), \"test\": defaultdict(list)}\n",
    "for dataset_name, dataset in personachat.items():\n",
    "    num_candidates = len(dataset[0][\"utterances\"][0][\"candidates\"])\n",
    "    if args.num_candidates > 0 and dataset_name == 'train':\n",
    "        num_candidates = min(args.num_candidates, num_candidates)\n",
    "    for dialog in dataset:\n",
    "        persona = dialog[\"personality\"].copy()\n",
    "        for _ in range(args.personality_permutations):\n",
    "            for utterance in dialog[\"utterances\"]:\n",
    "                history = utterance[\"history\"][-(2*args.max_history+1):]\n",
    "                for j, candidate in enumerate(utterance[\"candidates\"][-num_candidates:]):\n",
    "                    lm_labels = bool(j == num_candidates-1)\n",
    "#                     instance, _ = build_input_from_segments(persona, history, candidate, tokenizer, lm_labels)\n",
    "#                     for input_name, input_array in instance.items():\n",
    "#                         datasets[dataset_name][input_name].append(input_array)\n",
    "#                 datasets[dataset_name][\"mc_labels\"].append(num_candidates - 1)\n",
    "#                 datasets[dataset_name][\"n_candidates\"] = num_candidates\n",
    "#             persona = [persona[-1]] + persona[:-1]  # permuted personalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T07:26:25.440915Z",
     "start_time": "2019-07-09T07:26:25.345574Z"
    }
   },
   "outputs": [],
   "source": [
    "def _truncate_seq_pair_n(tokens, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    # from https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_classifier_dataset_utils.py#L482\n",
    "    while True:\n",
    "        total_length = sum(len(s) for s in tokens)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        longest = sorted(tokens, key=len, reverse=True)[0]\n",
    "        longest.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T07:32:06.968302Z",
     "start_time": "2019-07-09T07:32:06.855137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40478, 3260], [40481, 269, 269, 269, 269, 252, 40477, 28168, 271, 11240, 16260, 492, 970, 1, 507, 278, 13, 24, 21, 9, 53, 12, 53, 17, 12, 50, 53, 43, 20343, 28, 24, 268, 40477, 616, 1120, 925, 510, 6907, 40477, 269, 269, 269, 269, 514, 15925, 13, 44, 265], [40480, 269, 269, 269, 269, 241, 15925, 13, 44, 265, 40477, 1288, 640, 481, 3269, 249, 925, 669, 520, 8955, 510, 239, 40477, 269, 269, 269, 269, 590, 2151, 21, 2041, 14, 251], [40481, 269, 269, 269, 269, 255, 2151, 21, 2041, 14, 251, 40477, 912, 520, 899, 551, 485, 580, 487, 40477, 269, 269, 269, 269, 483, 2151, 21, 30, 712, 268], [40480, 269, 269, 269, 269, 255, 2151, 21, 30, 712, 268, 40477, 568, 507, 942, 773, 40477, 269, 269, 269, 269, 483, 2151, 21, 23437, 261, 40479]]\n"
     ]
    }
   ],
   "source": [
    "# Now look at the build input to find where we should clip\n",
    "reply=candidate\n",
    "with_eos=True\n",
    "# build_input_from_segments(persona, history, candidate, tokenizer, lm_labels)\n",
    "bos, eos, speaker1, speaker2 = tokenizer.convert_tokens_to_ids(SPECIAL_TOKENS[:-1])\n",
    "\n",
    "tokenizer.max_len\n",
    "\n",
    "instance = {}\n",
    "sequence = [[bos] + list(chain(*persona))] + history + [reply + ([eos] if with_eos else [])]\n",
    "sequence = [sequence[0]] + [[speaker2 if (len(sequence)-i) % 2 else speaker1] + s for i, s in enumerate(sequence[1:])]\n",
    "print(sequence)\n",
    "sequence2 = sequence\n",
    "\n",
    "instance[\"input_ids\"] = list(chain(*sequence))\n",
    "instance[\"token_type_ids\"] = [speaker2 if i % 2 else speaker1 for i, s in enumerate(sequence) for _ in s]\n",
    "instance[\"mc_token_ids\"] = len(instance[\"input_ids\"]) - 1\n",
    "instance[\"lm_labels\"] = [-1] * len(instance[\"input_ids\"])\n",
    "if lm_labels:\n",
    "    instance[\"lm_labels\"] = ([-1] * sum(len(s) for s in sequence[:-1])) + [-1] + sequence[-1][1:]\n",
    "    \n",
    "assert len(instance[\"input_ids\"]) < tokenizer.max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T07:34:41.916737Z",
     "start_time": "2019-07-09T07:34:41.824453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(history), len(sequence)\n",
    "tokenizer.max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T07:35:12.029029Z",
     "start_time": "2019-07-09T07:35:11.922265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40478, 3260], [269, 269, 269, 269, 252, 40477, 28168, 271, 11240, 16260, 492, 970, 1, 507, 278, 13, 24, 21, 9, 53, 12, 53, 17], [269, 269, 269, 269, 241, 15925, 13, 44, 265, 40477, 1288, 640, 481, 3269, 249, 925, 669, 520, 8955, 510, 239, 40477, 269], [269, 269, 269, 269, 255, 2151, 21, 2041, 14, 251, 40477, 912, 520, 899, 551, 485, 580, 487, 40477, 269, 269, 269, 269], [269, 269, 269, 269, 255, 2151, 21, 30, 712, 268, 40477, 568, 507, 942, 773, 40477, 269, 269, 269, 269, 483, 2151, 21, 23437, 40479]]\n",
      "[[40478, 3260], [40481, 269, 269, 269, 269, 252, 40477, 28168, 271, 11240, 16260, 492, 970, 1, 507, 278, 13, 24, 21, 9, 53, 12, 53, 17], [40480, 269, 269, 269, 269, 241, 15925, 13, 44, 265, 40477, 1288, 640, 481, 3269, 249, 925, 669, 520, 8955, 510, 239, 40477, 269], [40481, 269, 269, 269, 269, 255, 2151, 21, 2041, 14, 251, 40477, 912, 520, 899, 551, 485, 580, 487, 40477, 269, 269, 269, 269], [40480, 269, 269, 269, 269, 255, 2151, 21, 30, 712, 268, 40477, 568, 507, 942, 773, 40477, 269, 269, 269, 269, 483, 2151, 21, 23437, 40479]]\n"
     ]
    }
   ],
   "source": [
    "instance = {}\n",
    "sequence = [list(chain(*persona))] + history + [reply ]\n",
    "\n",
    "# clip the chat history, by removing from the longest message\n",
    "_truncate_seq_pair_n(sequence, tokenizer.max_len - len(history) - 2 - with_eos)\n",
    "persona_c = sequence[0]\n",
    "history_c = sequence[1:-1]\n",
    "reply_c = sequence[-1]\n",
    "\n",
    "# add tokens\n",
    "sequence = [[bos] + persona_c] + history_c + [reply_c + ([eos] if with_eos else [])]\n",
    "print(sequence)\n",
    "# add speaker tokens\n",
    "sequence = [sequence[0]] + [[speaker2 if (len(sequence)-i) % 2 else speaker1] + s for i, s in enumerate(sequence[1:])]\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T07:35:02.139179Z",
     "start_time": "2019-07-09T07:35:02.032969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 24, 24, 24, 26], 100)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = [len(s) for s in sequence]\n",
    "ll, sum(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T07:31:38.036494Z",
     "start_time": "2019-07-09T07:31:37.937953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 47, 32, 29, 26]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =[[bos] + list(chain(*persona))] + history + [reply + ([eos] if with_eos else [])]\n",
    "[len(s) for s in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T07:15:08.994201Z",
     "start_time": "2019-07-09T07:15:08.895957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 140, 140)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(instance[\"input_ids\"]), len(instance[\"token_type_ids\"]), len(instance[\"lm_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T07:19:38.199840Z",
     "start_time": "2019-07-09T07:19:38.124037Z"
    }
   },
   "outputs": [],
   "source": [
    "remaining_len = tokenizer.max_len - len(list(chain(*persona))) - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T07:18:22.711657Z",
     "start_time": "2019-07-09T07:18:22.619506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 108)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reply), len(list(chain(*history)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T03:56:46.274621Z",
     "start_time": "2019-07-09T03:56:46.223967Z"
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"Pad inputs and convert to Tensor\")\n",
    "tensor_datasets = {\"train\": [], \"valid\": [], \"test\": []}\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    dataset = pad_dataset(dataset, padding=tokenizer.convert_tokens_to_ids(SPECIAL_TOKENS[-1]))\n",
    "    for input_name in MODEL_INPUTS:\n",
    "        tensor = torch.tensor(dataset[input_name])\n",
    "        if input_name != \"mc_labels\":\n",
    "            tensor = tensor.view((-1, datasets[dataset_name][\"n_candidates\"]) + tensor.shape[1:])\n",
    "        tensor_datasets[dataset_name].append(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Build train and validation dataloaders\")\n",
    "train_dataset, valid_dataset = TensorDataset(*tensor_datasets[\"train\"]), TensorDataset(*tensor_datasets[\"valid\"])\n",
    "train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset) if args.distributed else None\n",
    "valid_sampler = torch.utils.data.distributed.DistributedSampler(valid_dataset) if args.distributed else None\n",
    "train_loader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, shuffle=(not args.distributed))\n",
    "valid_loader = DataLoader(valid_dataset, sampler=valid_sampler, batch_size=args.valid_batch_size, shuffle=False)\n",
    "\n",
    "logger.info(\"Train dataset (Batch, Candidates, Seq length): {}. Batches: {}\".format(train_dataset.tensors[0].shape, len(train_dataset)))\n",
    "logger.info(\"Valid dataset (Batch, Candidates, Seq length): {}, Batches: {}\".format(valid_dataset.tensors[0].shape, len(valid_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:25:46.058046Z",
     "start_time": "2019-07-09T05:25:46.017266Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_loader, val_loader, train_sampler, valid_sampler = get_data_loaders(args, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:25:46.197520Z",
     "start_time": "2019-07-09T05:25:46.165650Z"
    }
   },
   "outputs": [],
   "source": [
    "# from utils import PERSONACHAT_URL, HF_FINETUNED_MODEL, cached_path\n",
    "# dataset_path=args.dataset_path\n",
    "# dataset_cache=args.dataset_cache\n",
    "# dataset_path = dataset_path or PERSONACHAT_URL\n",
    "# dataset_cache = dataset_cache + '_' + type(tokenizer).__name__  # Do avoid using GPT cache for GPT-2 and vice-versa\n",
    "\n",
    "# personachat_file = cached_path(dataset_path)\n",
    "# with open(personachat_file, \"r\", encoding=\"utf-8\") as f:\n",
    "#     dataset = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:26:14.688830Z",
     "start_time": "2019-07-09T05:26:14.637556Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_dataset(tokenizer, dataset_path, dataset_cache=None):\n",
    "#     \"\"\" Get PERSONACHAT from S3 \"\"\"\n",
    "#     dataset_path = dataset_path or PERSONACHAT_URL\n",
    "#     dataset_cache = dataset_cache + '_' + type(tokenizer).__name__  # Do avoid using GPT cache for GPT-2 and vice-versa\n",
    "#     if dataset_cache and os.path.isfile(dataset_cache):\n",
    "#         logger.info(\"Load tokenized dataset from cache at %s\", dataset_cache)\n",
    "#         dataset = torch.load(dataset_cache)\n",
    "#     else:\n",
    "#         logger.info(\"Download dataset from %s\", dataset_path)\n",
    "#         personachat_file = cached_path(dataset_path)\n",
    "#         with open(personachat_file, \"r\", encoding=\"utf-8\") as f:\n",
    "#             dataset = json.loads(f.read())\n",
    "\n",
    "#         logger.info(\"Tokenize and encode the dataset\")\n",
    "#         def tokenize(obj):\n",
    "#             if isinstance(obj, str):\n",
    "#                 return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(obj))\n",
    "#             if isinstance(obj, dict):\n",
    "#                 return dict((n, tokenize(o)) for n, o in obj.items())\n",
    "#             return list(tokenize(o) for o in obj)\n",
    "#         dataset = tokenize(dataset)\n",
    "#         if dataset_cache:\n",
    "#             torch.save(dataset, dataset_cache)\n",
    "#     return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:26:14.974021Z",
     "start_time": "2019-07-09T05:26:14.927441Z"
    }
   },
   "outputs": [],
   "source": [
    "# # def get_data_loaders(args, tokenizer):\n",
    "# \"\"\" Prepare the dataset for training and evaluation \"\"\"\n",
    "# personachat = get_dataset(tokenizer, args.dataset_path, args.dataset_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T04:53:09.555459Z",
     "start_time": "2019-07-09T04:53:09.437039Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:26:15.277961Z",
     "start_time": "2019-07-09T05:26:15.229578Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(personachat.keys(), personachat['train'][0].keys())\n",
    "# \"\"\"\n",
    "# We can pass in history as previous comments\n",
    "# persona... none. Or OP\n",
    "# speaker... yeah leave it as 1,2,1,2 for now\n",
    "# so all it's doing it putting it in order\n",
    "# \"\"\"\n",
    "# print('persona', [tokenizer.decode(p) for p in persona])\n",
    "# print('history', [tokenizer.decode(p) for p in history])\n",
    "# print('candidate', tokenizer.decode(candidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:33:29.196416Z",
     "start_time": "2019-07-09T05:33:29.151760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(chain(*personalities.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:26:17.044333Z",
     "start_time": "2019-07-09T05:26:16.995181Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Load reddit comments from pickles\n",
    "# from pathlib import Path\n",
    "# import pickle\n",
    "# data_dir = Path('../data/reddit_threads/')\n",
    "# subreddit_paths = [d for d in data_dir.glob('*/') if d.is_dir()]\n",
    "# subreddit_path = subreddit_paths[0]\n",
    "# # print(subreddit_path)\n",
    "# subreddit_files = sorted(subreddit_path.glob('*.pickle'))\n",
    "# print(len(subreddit_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:26:17.329114Z",
     "start_time": "2019-07-09T05:26:17.277926Z"
    }
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# import copy\n",
    "# import collections\n",
    "        \n",
    "# def get_id_for_comments(thing):\n",
    "#     if thing[\"type\"] == \"submission\":\n",
    "#         return \"t3_\" + thing[\"id\"]\n",
    "#     else:\n",
    "#         return \"t1_\" + thing[\"id\"]\n",
    "    \n",
    "# def thread2queue(comment_dict, submission):\n",
    "#     # Now we want to reconstruct the comment heirachy.\n",
    "#     # 0. Init with the submission in the queue. start with this as target\n",
    "#     # 1. Look at target item in the queue, find it's top rated child comment\n",
    "#     #  1a. If it has one, pop it out, put it at end of queue, go to 1\n",
    "#     #  1b. If it doesn't have comment left, go to previous item in queue\n",
    "#     comment_dict = copy.deepcopy(comment_dict)\n",
    "#     queue = [submission]\n",
    "#     submission_id = get_id_for_comments(submission)\n",
    "#     while len(list(itertools.chain(*comment_dict.values()))) > 0:\n",
    "#         for queue_position in range(len(queue) - 1, -1, -1):\n",
    "#             current_id = get_id_for_comments(queue[queue_position])\n",
    "#             found = comment_dict[current_id]\n",
    "#             if len(found):\n",
    "#                 break\n",
    "#         next_comment = comment_dict[current_id].pop()\n",
    "#         queue.append(next_comment)\n",
    "\n",
    "#     # now format\n",
    "#     return queue\n",
    "\n",
    "# def format_thing(thing, submission_id, tokenizer):\n",
    "#     \"\"\"Format a submission or comment using special tokens and tokens\"\"\"\n",
    "#     def tokenize(obj):\n",
    "#         return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(obj))\n",
    "#     bos, eos, speaker1, speaker2, pad, S, ES, R, ER, T, ET = tokenizer.convert_tokens_to_ids(SPECIAL_TOKENS)\n",
    "#     if thing[\"type\"] == \"submission\":\n",
    "#         return (\n",
    "#             [S]\n",
    "#             + tokenize(\"\\n\".join([thing[\"url\"], thing[\"title\"], thing[\"selftext\"]]))\n",
    "#             + [ES ]\n",
    "#             + tokenize(thing[\"id\"])\n",
    "#         )\n",
    "#     elif thing[\"parent_id\"] == submission_id:\n",
    "#         return (\n",
    "#             [T]\n",
    "#             + tokenize(thing[\"parent_id\"][3:] + \"\\n\")            \n",
    "#             + tokenize(thing[\"body\"])\n",
    "#             + [ET]\n",
    "#             + tokenize(thing[\"id\"])\n",
    "#         )\n",
    "#     else:\n",
    "#         return (\n",
    "#             [R]\n",
    "#             + tokenize(thing[\"parent_id\"][3:]\n",
    "#             + \"\\n\"\n",
    "#             + thing[\"body\"])\n",
    "#             + [ER]\n",
    "#             + tokenize(thing[\"id\"])\n",
    "#         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:26:17.503294Z",
     "start_time": "2019-07-09T05:26:17.453007Z"
    }
   },
   "outputs": [],
   "source": [
    "# def build_input_from_segments(thread, tokenizer, lm_labels=False, with_eos=True):\n",
    "#     \"\"\" Build a sequence of input from 3 segments: persona, history and last reply \"\"\"\n",
    "#     bos, eos, speaker1, speaker2, pad, S, ES, R, ER, T, ET = tokenizer.convert_tokens_to_ids(SPECIAL_TOKENS)\n",
    "    \n",
    "#     # So build sequence from reddit comments\n",
    "#     queue = thread2queue(thread['comment_dict'], thread['submission'])\n",
    "#     submission_id = get_id_for_comments(queue[0])\n",
    "#     queue_tokens = [format_thing(thing, submission_id, tokenizer) for thing in queue]\n",
    "#     queue_tokens = list(itertools.chain(*queue_tokens))\n",
    "\n",
    "#     instance = {}\n",
    "#     sequence = [bos] + queue_tokens + ([eos] if with_eos else [])\n",
    "\n",
    "#     instance[\"input_ids\"] = sequence\n",
    "#     instance[\"token_type_ids\"] = [speaker2 if i % 2 else speaker1 for i, s in enumerate(sequence)]\n",
    "#     instance[\"mc_token_ids\"] = len(instance[\"input_ids\"]) - 1\n",
    "#     instance[\"lm_labels\"] = [-1] * len(instance[\"input_ids\"])\n",
    "#     if lm_labels:\n",
    "#         instance[\"lm_labels\"] = ([-1] * sum(len(s) for s in sequence[:-1])) + [-1] + sequence[-1][1:]\n",
    "#     return instance, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T04:51:52.593440Z",
     "start_time": "2019-07-09T04:51:52.545203Z"
    }
   },
   "outputs": [],
   "source": [
    "# thread = pickle.load(subreddit_files[10].open('rb'))\n",
    "# instance, sequence = build_input_from_segments(thread, tokenizer, lm_labels=False)\n",
    "# print(tokenizer.decode(instance['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thread to persona json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T04:51:52.908437Z",
     "start_time": "2019-07-09T04:51:52.856159Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:26:38.240228Z",
     "start_time": "2019-07-09T05:26:27.140118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train/singularity', max=569, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/reddit_threads/singularity/t3_9r9hpa.pickle pop from empty list\n",
      "../data/reddit_threads/singularity/t3_9j3ciq.pickle pop from empty list\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train/totallynotrobots', max=810, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/reddit_threads/totallynotrobots/t3_8yrj86.pickle pop from empty list\n",
      "../data/reddit_threads/totallynotrobots/t3_9tp6nq.pickle pop from empty list\n",
      "../data/reddit_threads/totallynotrobots/t3_947zsn.pickle pop from empty list\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train/aww', max=72, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/reddit_threads/aww/t3_camn17.pickle pop from empty list\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid/singularity', max=64, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid/totallynotrobots', max=90, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/reddit_threads/totallynotrobots/t3_9zbfqf.pickle pop from empty list\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='valid/aww', max=9, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='test/singularity', max=71, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='test/totallynotrobots', style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='test/aww', max=9, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:../data.py:Tokenize and encode the dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "dataset2 = get_dataset(tokenizer, '../data/reddit_threads/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:02:42.242468Z",
     "start_time": "2019-07-09T05:02:42.196030Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_input_from_segments(persona, history, reply, tokenizer, lm_labels=False, with_eos=True):\n",
    "    \"\"\" Build a sequence of input from 3 segments: persona, history and last reply \"\"\"\n",
    "    bos, eos, speaker1, speaker2 = tokenizer.convert_tokens_to_ids(SPECIAL_TOKENS[:-1])\n",
    "\n",
    "    instance = {}\n",
    "    sequence = [[bos] + list(chain(*persona))] + history + [reply + ([eos] if with_eos else [])]\n",
    "    sequence = [sequence[0]] + [[speaker2 if (len(sequence)-i) % 2 else speaker1] + s for i, s in enumerate(sequence[1:])]\n",
    "\n",
    "    instance[\"input_ids\"] = list(chain(*sequence))\n",
    "    instance[\"token_type_ids\"] = [speaker2 if i % 2 else speaker1 for i, s in enumerate(sequence) for _ in s]\n",
    "    instance[\"mc_token_ids\"] = len(instance[\"input_ids\"]) - 1\n",
    "    instance[\"lm_labels\"] = [-1] * len(instance[\"input_ids\"])\n",
    "    if lm_labels:\n",
    "        instance[\"lm_labels\"] = ([-1] * sum(len(s) for s in sequence[:-1])) + [-1] + sequence[-1][1:]\n",
    "    return instance, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:03:52.069743Z",
     "start_time": "2019-07-09T05:03:51.672355Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:../train.py:Build inputs and labels\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Build inputs and labels\")\n",
    "datasets = {\"train\": defaultdict(list), \"valid\": defaultdict(list), \"test\": defaultdict(list)}\n",
    "for dataset_name, dataset in personachat.items():\n",
    "    num_candidates = len(dataset[0][\"utterances\"][0][\"candidates\"])\n",
    "    if args.num_candidates > 0 and dataset_name == 'train':\n",
    "        num_candidates = min(args.num_candidates, num_candidates)\n",
    "    for dialog in dataset:\n",
    "        persona = dialog[\"personality\"].copy()\n",
    "        for _ in range(args.personality_permutations):\n",
    "            for utterance in dialog[\"utterances\"]:\n",
    "                history = utterance[\"history\"][-(2*args.max_history+1):]\n",
    "                for j, candidate in enumerate(utterance[\"candidates\"][-num_candidates:]):\n",
    "                    lm_labels = bool(j == num_candidates-1)\n",
    "                    instance, _ = build_input_from_segments(persona, history, candidate, tokenizer, lm_labels)\n",
    "                    for input_name, input_array in instance.items():\n",
    "                        datasets[dataset_name][input_name].append(input_array)\n",
    "                datasets[dataset_name][\"mc_labels\"].append(num_candidates - 1)\n",
    "                datasets[dataset_name][\"n_candidates\"] = num_candidates\n",
    "            persona = [persona[-1]] + persona[:-1]  # permuted personalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:01:55.129883Z",
     "start_time": "2019-07-09T05:01:55.078192Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T02:38:47.764467Z",
     "start_time": "2019-07-09T02:38:47.758208Z"
    }
   },
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:04:03.831554Z",
     "start_time": "2019-07-09T05:04:03.791874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys dict_keys(['input_ids', 'token_type_ids', 'mc_token_ids', 'lm_labels', 'mc_labels', 'n_candidates'])\n",
      "input_ids [[40478, 17574, 22863, 40481, 269, 269, 269, 269, 255, 26281, 44, 559, 265, 512, 759, 256, 241, 3394, 12975, 244, 485, 728, 11101, 240, 485, 1909, 240, 488, 485, 4571, 244, 485, 8888, 239, 645, 600, 759, 256, 241, 6920, 649, 768, 240, 895, 636, 249, 1533, 257, 512, 604, 485, 1168, 688, 481, 3371, 485, 6920, 562, 688, 485, 1629, 6920, 239, 895, 636, 249, 1441, 512, 645, 512, 972, 510, 512, 825, 600, 604, 6417, 257, 249, 759, 256, 241, 580, 500, 754, 1082, 485, 699, 525, 239, 249, 727, 599, 512, 640, 1887, 240, 249, 976, 587, 240, 568, 249, 4484, 485, 1441, 525, 3555, 759, 256, 241, 580, 6787, 485, 3366, 240, 507, 28989, 247, 256, 241, 1621, 645, 600, 604, 6804, 522, 595, 239, 249, 1048, 2805, 525, 616, 759, 580, 1295, 557, 8238, 8103, 239, 3555, 1550, 7692, 4569, 247, 256, 241, 7750, 768, 240, 525, 636, 580, 547, 1579, 239, 249, 1048, 668, 1565, 670, 599, 256, 252, 1198, 562, 481, 1879, 4115, 239, 606, 994, 580, 1295, 557, 4187, 240, 595, 649, 1662, 239, 3555, 994, 699, 754, 1082, 488, 1129, 562, 768, 1147, 4191, 1033, 500, 2294, 240, 525, 638, 606, 759, 8052, 5860, 989, 2310, 256, 241, 604, 485, 1129, 3118, 600, 4484, 485, 587, 620, 488, 525, 600, 759, 3545, 754, 25176, 2190, 485, 1076, 31427, 276, 664, 1621, 718, 13083, 240, 600, 640, 668, 8613, 275, 239, 3681, 510, 568, 4240, 544, 595, 547, 929, 4636, 488, 547, 22855, 713, 12084, 6074, 640, 7369, 239, 269, 269, 269, 269, 483, 26281, 25, 12354, 282, 40480, 269, 269, 269, 269, 255, 26281, 25, 12354, 282, 587, 512, 1441, 500, 775, 38535, 257, 269, 269, 269, 269, 483, 646, 48, 5, 42, 23, 247, 40481, 269, 269, 269, 269, 255, 646, 48, 5, 42, 23, 247, 664, 240, 249, 1048, 531, 30073, 1918, 239, 249, 868, 2994, 895, 989, 1441, 500, 4187, 240, 6656, 488, 589, 525, 2404, 239, 269, 269, 269, 269, 483, 646, 43, 10, 46, 35820, 40480, 269, 269, 269, 269, 255, 646, 43, 10, 46, 35820, 525, 256, 252, 870, 485, 1344, 239, 645, 512, 1441, 2217, 525, 6417, 544, 15655, 531, 2564, 6350, 5358, 498, 1621, 240, 599, 256, 252, 481, 17274, 562, 2164, 525, 655, 544, 246, 22165, 23249, 1210, 481, 3371, 562, 8888, 488, 13737, 25549, 485, 6920, 257, 595, 557, 1068, 640, 1873, 240, 568, 525, 507, 812, 1120, 580, 481, 1703, 239, 269, 269, 269, 269, 483, 646, 44, 10, 39, 25318, 40481, 269, 269, 269, 269, 255, 646, 44, 10, 39, 25318, 895, 587, 606, 6920, 257, 606, 6920, 912, 498, 1652, 240, 4068, 522, 6156, 240, 507, 256, 252, 595, 670, 1036, 817, 485, 580, 8534, 239, 557, 928, 557, 606, 604, 3205, 1959, 715, 622, 23178, 606, 759, 1120, 925, 3555, 1147, 481, 3371, 485, 6920, 239, 606, 1359, 6920, 912, 498, 481, 4026, 498, 2690, 239, 568, 240, 562, 6989, 240, 485, 1184, 8, 5514, 240, 595, 1550, 2471, 544, 595, 11445, 239, 895, 257, 912, 600, 868, 942, 481, 966, 239, 507, 256, 252, 481, 1164, 615, 556, 3555, 271, 645, 600, 868, 942, 481, 966, 600, 5011, 256, 241, 966, 2690, 239, 606, 759, 1359, 5659, 5526, 498, 2690, 525, 2310, 256, 241, 966, 768, 485, 1168, 688, 9535, 239, 606, 759, 1359, 925, 3555, 525, 812, 823, 485, 4103, 768, 1147, 2674, 562, 1033, 239, 890, 491, 768, 3366, 240, 606, 4300, 9014, 485, 4187, 1147, 1550, 4461, 485, 1441, 525, 244, 1436, 244, 4126, 246, 1877, 670, 768, 239, 620, 7820, 240, 645, 1184, 21156, 531, 3555, 763, 2443, 485, 604, 7692, 488, 580, 649, 566, 498, 768, 507, 1195, 10, 247, 256, 241, 580, 1252, 491, 589, 239, 606, 994, 1959, 1076, 31872, 500, 246, 13820, 4094, 239, 604, 512, 1295, 33220, 276, 481, 4121, 275, 257, 481, 3555, 11335, 2315, 617, 599, 606, 823, 617, 507, 488, 507, 5046, 3625, 989, 1147, 13218, 239, 599, 606, 636, 823, 544, 531, 3555, 649, 6028, 22691, 240, 566, 525, 3013, 768, 1147, 2674, 562, 1033, 500, 2294, 239, 645, 512, 640, 481, 15676, 488, 704, 7372, 640, 32605, 240, 2310, 256, 241, 512, 825, 525, 512, 994, 587, 1180, 500, 704, 1820, 485, 7750, 8126, 1698, 498, 7364, 5644, 12064, 556, 754, 1074, 11378, 257, 512, 640, 1419, 1565, 271, 244, 645, 600, 759, 30232, 622, 12972, 240, 600, 1259, 580, 649, 989, 834, 244, 240, 488, 507, 28989, 247, 256, 241, 966, 485, 580, 649, 525, 239, 507, 256, 252, 668, 531, 19482, 4512, 562, 622, 1074, 7750, 239, 269, 269, 269, 269, 483, 646, 44, 13, 521, 258, 40480, 269, 269, 269, 269, 255, 646, 44, 13, 521, 258, 296, 30045, 270, 244, 645, 600, 759, 30232, 622, 12972, 240, 600, 1259, 580, 649, 989, 834, 244, 240, 488, 507, 28989, 247, 256, 241, 966, 485, 580, 649, 525, 239, 507, 256, 252, 668, 531, 19482, 4512, 562, 622, 1074, 7750, 239, 3252, 525, 616, 544, 481, 808, 1774, 895, 606, 825, 3366, 488, 4571, 640, 3979, 649, 606, 640, 239, 269, 269, 269, 269, 483, 646, 54, 53, 30, 48, 280, 40479]]\n",
      "token_type_ids [[40480, 40480, 40480, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40481, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480, 40480]]\n",
      "mc_token_ids [861]\n",
      "lm_labels [[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]\n",
      "mc_labels [1]\n",
      "n_candidates 2\n"
     ]
    }
   ],
   "source": [
    "print('keys', datasets['train'].keys())\n",
    "for key in datasets['train'].keys():\n",
    "    d = datasets['train'][key]\n",
    "    if isinstance(d, list):\n",
    "        print(key, d[:1])\n",
    "    else: print(key, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:04:05.551752Z",
     "start_time": "2019-07-09T05:04:04.150823Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:../train.py:Pad inputs and convert to Tensor\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 3, 1375]' is invalid for input of size 413875",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-6bccafd4e40b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"mc_labels\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_candidates\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mtensor_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 3, 1375]' is invalid for input of size 413875"
     ]
    }
   ],
   "source": [
    "logger.info(\"Pad inputs and convert to Tensor\")\n",
    "tensor_datasets = {\"train\": [], \"valid\": []}\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    dataset = pad_dataset(dataset, padding=tokenizer.convert_tokens_to_ids(SPECIAL_TOKENS[-1]))\n",
    "    for input_name in MODEL_INPUTS:\n",
    "        tensor = torch.tensor(dataset[input_name])\n",
    "        if input_name != \"mc_labels\":\n",
    "            tensor = tensor.view((-1, datasets[dataset_name][\"n_candidates\"]) + tensor.shape[1:])\n",
    "        tensor_datasets[dataset_name].append(tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T05:04:05.555630Z",
     "start_time": "2019-07-09T05:04:04.800Z"
    }
   },
   "outputs": [],
   "source": [
    "logger.info(\"Build train and validation dataloaders\")\n",
    "train_dataset, valid_dataset = TensorDataset(*tensor_datasets[\"train\"]), TensorDataset(*tensor_datasets[\"valid\"])\n",
    "train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset) if args.distributed else None\n",
    "valid_sampler = torch.utils.data.distributed.DistributedSampler(valid_dataset) if args.distributed else None\n",
    "train_loader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, shuffle=(not args.distributed))\n",
    "valid_loader = DataLoader(valid_dataset, sampler=valid_sampler, batch_size=args.valid_batch_size, shuffle=False)\n",
    "\n",
    "logger.info(\"Train dataset (Batch, Candidates, Seq length): {}\".format(train_dataset.tensors[0].shape))\n",
    "logger.info(\"Valid dataset (Batch, Candidates, Seq length): {}\".format(valid_dataset.tensors[0].shape))\n",
    "train_loader, valid_loader, train_sampler, valid_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jup3.7.2",
   "language": "python",
   "name": "jup3.7.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
